{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install cbpro \n",
    "import cbpro\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # basic psycopg2 usage (not directly compatible with postgresql) \n",
    "# conn = psycopg2.connect(\"dbname=finanz user=kenny\")\n",
    "# # Open a cursor to perform database operations\n",
    "# cur = conn.cursor()\n",
    "# # cur.execute(\"INSERT INTO symbols (string) VALUES('ETH-EUR');\")\n",
    "# cur.execute(\"SELECT * FROM symbols;\")\n",
    "# cur.fetchone()\n",
    "# conn.commit() # persist the changes and clsoe the cursor and the connection \n",
    "# cur.close() \n",
    "# conn.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get password for kenny user \n",
    "def connect2DB(user):\n",
    "    pwd = getpass.getpass(\"Get password for {}\".format(user))\n",
    "    # and create a connection to posgresql or use sqlalchemy \n",
    "    db_engine = sqlalchemy.create_engine('postgresql+psycopg2://{}:{}@localhost/finanz'.format(user,pwd), pool_recycle=3600)\n",
    "    db_conn = db_engine.connect()\n",
    "    return db_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKERS = ['ETH-EUR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Get password for kenny ············\n"
     ]
    }
   ],
   "source": [
    "db_conn = connect2DB(\"kenny\")\n",
    "\n",
    "# Read data from PostgreSQL database table and load into a DataFrame instance\n",
    "symbols = pd.read_sql(\"select * from symbols where symbol IN ({}) \".format(\",\".join([\"'{}'\".format(t) for t in TICKERS])), db_conn, )\n",
    "candles = pd.read_sql(\"select * from candles where fk_symbol in ({})\".format(\",\".join([str(i) for i in symbols.id])), db_conn)\n",
    "columns = ['time','high','low','open','close','volume','resolution_sec', 'symbol','fk_symbol']\n",
    "df = candles.merge(symbols, left_on = \"fk_symbol\", right_on = \"id\")[columns]\n",
    "df.set_index([\"symbol\",\"time\"], inplace = True)\n",
    "db_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ETH-EUR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   symbol\n",
       "0   1  ETH-EUR"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>fk_symbol</th>\n",
       "      <th>resolution_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, time, high, low, open, close, volume, fk_symbol, resolution_sec]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api for getting historical data from cbpro\n",
    "pclient = cbpro.PublicClient()\n",
    "\n",
    "now_there = datetime.datetime.fromisoformat(pclient.get_time()[\"iso\"][0:-1]) # remove last item\n",
    "now_here = datetime.datetime.fromisoformat(datetime.datetime.now().isoformat())\n",
    "\n",
    "resolution = {\"1min\": 60 , \"5min\" : 300, \"15min\" : 900, \"1hr\" : 3600, \"6hr\" : 21600, \"1day\" : 86400}\n",
    "MAX_TICKERS = 200\n",
    "\n",
    "\n",
    "def reshape_data_for_analysis(df):\n",
    "    return df.merge(symbols, left_on='symbol', right_on = \"symbol\").rename(columns = {\"id\":\"fk_symbol\"}).set_index([\"symbol\",\"time\"])\n",
    "    \n",
    "def reshape_data_for_db(df):\n",
    "    return df.reset_index().drop(['symbol'], axis = 1)\n",
    "\n",
    "def convert_candles_to_df(candles, ticker, granularity):\n",
    "    \"\"\"\n",
    "    convert the data candles from the raw coinbase request to dataframe \n",
    "    \n",
    "    `index = time , columns = { low, high, open, close, volume },\n",
    "     [ 1415398768, 0.32, 4.2, 0.35, 4.2, 12.3 ],\n",
    "    :param: candles \n",
    "    :return: dataframe \n",
    "    \"\"\"\n",
    "    df= pd.DataFrame(columns = [\"time\",\"low\",\"high\",\"open\",\"close\",\"volume\"], data = candles)\n",
    "    df[\"time\"] = df[\"time\"].apply(lambda x : datetime.datetime.fromtimestamp(x))\n",
    "    df[\"symbol\"] = ticker\n",
    "    df[\"resolution_sec\"] = resolution[granularity]\n",
    "    return reshape_data_for_analysis(df)\n",
    "  \n",
    "\n",
    "def get_num_candles(begin, end, granularity):\n",
    "    \"\"\"\n",
    "    how many candles of `granularity` are in the interval [begin; end]\n",
    "    \"\"\"\n",
    "    return int((end - begin).total_seconds() // resolution[granularity])\n",
    "\n",
    "def get_data(client, ticker, begin, end,granularity):\n",
    "    \"\"\"\n",
    "    fetch historical ticker data for the time period [begin;end] with granularity `granularity`\n",
    "    :param: client the api client instance to query\n",
    "    :param: ticker the ticker to fetch data for \n",
    "    :param: begin the time from which to get data \n",
    "    :param: end the time to which to get data \n",
    "    :param: granularity a string representing the granularity of the data, i.e. `1min`, `5min` etc.\n",
    "    :return: directly the cbpro api response (a list of lists of values [ time, low, high, open, close, volume ])\n",
    "    \"\"\"\n",
    "    return client.get_product_historic_rates(ticker, \n",
    "                                             start = begin.isoformat(), \n",
    "                                             end = end.isoformat(),\n",
    "                                             granularity = resolution[granularity])\n",
    "\n",
    "def get_data_from(client, ticker, begin, size, granularity):\n",
    "    \"\"\"\n",
    "     fetch the `size` candles of `granularity` resolution, starting from `begin` timestamp\n",
    "     \n",
    "     :param: client the api client instance to query\n",
    "     :param: ticker the ticker to fetch data for \n",
    "     :param: begin the time from which to get data \n",
    "     :param: size the number of candles to fetch \n",
    "     :param: granularity a string representing the granularity of the data, i.e. `1min`, `5min` etc.\n",
    "     :return: a dataframe with the following columns (see example below)\n",
    "     \n",
    "     [ time, low, high, open, close, volume ],\n",
    "     [ 1415398768, 0.32, 4.2, 0.35, 4.2, 12.3 ],\n",
    "    \"\"\"\n",
    "    # size = q*MAX_TICKERS + r \n",
    "    q = size // MAX_TICKERS\n",
    "    r = size % MAX_TICKERS \n",
    "    \n",
    "    candles = []\n",
    "    # get q * MAX_TICKERS data\n",
    "    for i in range(q):\n",
    "        end = (begin + datetime.timedelta(seconds = MAX_TICKERS * resolution[granularity]))\n",
    "        print(\"Getting data from {} to {}\".format(begin, end))\n",
    "        candles = candles + get_data(client,ticker, begin, end, granularity)\n",
    "        begin = end\n",
    "      \n",
    "    # get residual data\n",
    "    end = (begin + datetime.timedelta(seconds = r * resolution[granularity]))\n",
    "    candles = candles + get_data(client, ticker, begin, end, granularity)    \n",
    "    return convert_candles_to_df(candles, ticker, granularity)\n",
    "    \n",
    "    \n",
    "def get_data_to(client, ticker, end, size, granularity):\n",
    "    \"\"\"\n",
    "     fetch the last `size` candles of `granularity` resolution, with respect to `end` timestamp\n",
    "     \n",
    "     :param: client the api client instance to query\n",
    "     :param: ticker the ticker to fetch data for \n",
    "     :param: end the time to which to get data \n",
    "     :param: size the number of candles to fetch \n",
    "     :param: granularity a string representing the granularity of the data, i.e. `1min`, `5min` etc.\n",
    "     :return: a dataframe with the following columns (see example below)\n",
    "     \n",
    "     [ time, low, high, open, close, volume ],\n",
    "     [ 1415398768, 0.32, 4.2, 0.35, 4.2, 12.3 ],\n",
    "    \"\"\"\n",
    "    # size = q*MAX_TICKERS + r \n",
    "    q = size // MAX_TICKERS\n",
    "    r = size % MAX_TICKERS \n",
    "       \n",
    "    candles = []\n",
    "    # get q * MAX_TICKERS data\n",
    "    for i in range(q):\n",
    "        begin = (end - datetime.timedelta(seconds = MAX_TICKERS * resolution[granularity]))\n",
    "        print(\"Getting data from {} to {}\".format(begin, end))\n",
    "        candles = candles + get_data(client,ticker, begin, end, granularity)\n",
    "        end = begin\n",
    "    \n",
    "    # get residual data\n",
    "    begin = (end - datetime.timedelta(seconds = r * resolution[granularity]))\n",
    "    candles = candles + get_data(client, ticker, begin, end, granularity)    \n",
    "    return convert_candles_to_df(candles, ticker, granularity)\n",
    "\n",
    "def get_data_range(client, ticker, begin, end, granularity):\n",
    "    size = get_num_candles(begin, end, granularity)\n",
    "    return get_data_from(client, ticker, begin, size, granularity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch 15 minute resolution data from 1st of Jan - 7 am to 12th of Feb 19:00 to now \n",
    "TICKER = \"ETH-EUR\"\n",
    "granularity = \"5min\"\n",
    "\n",
    "begin = datetime.datetime(2020,11,1)\n",
    "end = datetime.datetime(2021,2, 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30528"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_candles(begin, end, granularity)\n",
    "# df2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data from 2020-11-01 00:00:00 to 2020-11-01 16:40:00\n",
      "Getting data from 2020-11-01 16:40:00 to 2020-11-02 09:20:00\n",
      "Getting data from 2020-11-02 09:20:00 to 2020-11-03 02:00:00\n",
      "Getting data from 2020-11-03 02:00:00 to 2020-11-03 18:40:00\n",
      "Getting data from 2020-11-03 18:40:00 to 2020-11-04 11:20:00\n",
      "Getting data from 2020-11-04 11:20:00 to 2020-11-05 04:00:00\n",
      "Getting data from 2020-11-05 04:00:00 to 2020-11-05 20:40:00\n",
      "Getting data from 2020-11-05 20:40:00 to 2020-11-06 13:20:00\n",
      "Getting data from 2020-11-06 13:20:00 to 2020-11-07 06:00:00\n",
      "Getting data from 2020-11-07 06:00:00 to 2020-11-07 22:40:00\n",
      "Getting data from 2020-11-07 22:40:00 to 2020-11-08 15:20:00\n",
      "Getting data from 2020-11-08 15:20:00 to 2020-11-09 08:00:00\n",
      "Getting data from 2020-11-09 08:00:00 to 2020-11-10 00:40:00\n",
      "Getting data from 2020-11-10 00:40:00 to 2020-11-10 17:20:00\n",
      "Getting data from 2020-11-10 17:20:00 to 2020-11-11 10:00:00\n",
      "Getting data from 2020-11-11 10:00:00 to 2020-11-12 02:40:00\n",
      "Getting data from 2020-11-12 02:40:00 to 2020-11-12 19:20:00\n",
      "Getting data from 2020-11-12 19:20:00 to 2020-11-13 12:00:00\n",
      "Getting data from 2020-11-13 12:00:00 to 2020-11-14 04:40:00\n",
      "Getting data from 2020-11-14 04:40:00 to 2020-11-14 21:20:00\n",
      "Getting data from 2020-11-14 21:20:00 to 2020-11-15 14:00:00\n",
      "Getting data from 2020-11-15 14:00:00 to 2020-11-16 06:40:00\n",
      "Getting data from 2020-11-16 06:40:00 to 2020-11-16 23:20:00\n",
      "Getting data from 2020-11-16 23:20:00 to 2020-11-17 16:00:00\n",
      "Getting data from 2020-11-17 16:00:00 to 2020-11-18 08:40:00\n",
      "Getting data from 2020-11-18 08:40:00 to 2020-11-19 01:20:00\n",
      "Getting data from 2020-11-19 01:20:00 to 2020-11-19 18:00:00\n",
      "Getting data from 2020-11-19 18:00:00 to 2020-11-20 10:40:00\n",
      "Getting data from 2020-11-20 10:40:00 to 2020-11-21 03:20:00\n",
      "Getting data from 2020-11-21 03:20:00 to 2020-11-21 20:00:00\n",
      "Getting data from 2020-11-21 20:00:00 to 2020-11-22 12:40:00\n",
      "Getting data from 2020-11-22 12:40:00 to 2020-11-23 05:20:00\n",
      "Getting data from 2020-11-23 05:20:00 to 2020-11-23 22:00:00\n",
      "Getting data from 2020-11-23 22:00:00 to 2020-11-24 14:40:00\n",
      "Getting data from 2020-11-24 14:40:00 to 2020-11-25 07:20:00\n",
      "Getting data from 2020-11-25 07:20:00 to 2020-11-26 00:00:00\n",
      "Getting data from 2020-11-26 00:00:00 to 2020-11-26 16:40:00\n",
      "Getting data from 2020-11-26 16:40:00 to 2020-11-27 09:20:00\n",
      "Getting data from 2020-11-27 09:20:00 to 2020-11-28 02:00:00\n",
      "Getting data from 2020-11-28 02:00:00 to 2020-11-28 18:40:00\n",
      "Getting data from 2020-11-28 18:40:00 to 2020-11-29 11:20:00\n",
      "Getting data from 2020-11-29 11:20:00 to 2020-11-30 04:00:00\n",
      "Getting data from 2020-11-30 04:00:00 to 2020-11-30 20:40:00\n",
      "Getting data from 2020-11-30 20:40:00 to 2020-12-01 13:20:00\n",
      "Getting data from 2020-12-01 13:20:00 to 2020-12-02 06:00:00\n",
      "Getting data from 2020-12-02 06:00:00 to 2020-12-02 22:40:00\n",
      "Getting data from 2020-12-02 22:40:00 to 2020-12-03 15:20:00\n",
      "Getting data from 2020-12-03 15:20:00 to 2020-12-04 08:00:00\n",
      "Getting data from 2020-12-04 08:00:00 to 2020-12-05 00:40:00\n",
      "Getting data from 2020-12-05 00:40:00 to 2020-12-05 17:20:00\n",
      "Getting data from 2020-12-05 17:20:00 to 2020-12-06 10:00:00\n",
      "Getting data from 2020-12-06 10:00:00 to 2020-12-07 02:40:00\n",
      "Getting data from 2020-12-07 02:40:00 to 2020-12-07 19:20:00\n",
      "Getting data from 2020-12-07 19:20:00 to 2020-12-08 12:00:00\n",
      "Getting data from 2020-12-08 12:00:00 to 2020-12-09 04:40:00\n",
      "Getting data from 2020-12-09 04:40:00 to 2020-12-09 21:20:00\n",
      "Getting data from 2020-12-09 21:20:00 to 2020-12-10 14:00:00\n",
      "Getting data from 2020-12-10 14:00:00 to 2020-12-11 06:40:00\n",
      "Getting data from 2020-12-11 06:40:00 to 2020-12-11 23:20:00\n",
      "Getting data from 2020-12-11 23:20:00 to 2020-12-12 16:00:00\n",
      "Getting data from 2020-12-12 16:00:00 to 2020-12-13 08:40:00\n",
      "Getting data from 2020-12-13 08:40:00 to 2020-12-14 01:20:00\n",
      "Getting data from 2020-12-14 01:20:00 to 2020-12-14 18:00:00\n",
      "Getting data from 2020-12-14 18:00:00 to 2020-12-15 10:40:00\n",
      "Getting data from 2020-12-15 10:40:00 to 2020-12-16 03:20:00\n",
      "Getting data from 2020-12-16 03:20:00 to 2020-12-16 20:00:00\n",
      "Getting data from 2020-12-16 20:00:00 to 2020-12-17 12:40:00\n",
      "Getting data from 2020-12-17 12:40:00 to 2020-12-18 05:20:00\n",
      "Getting data from 2020-12-18 05:20:00 to 2020-12-18 22:00:00\n",
      "Getting data from 2020-12-18 22:00:00 to 2020-12-19 14:40:00\n",
      "Getting data from 2020-12-19 14:40:00 to 2020-12-20 07:20:00\n",
      "Getting data from 2020-12-20 07:20:00 to 2020-12-21 00:00:00\n",
      "Getting data from 2020-12-21 00:00:00 to 2020-12-21 16:40:00\n",
      "Getting data from 2020-12-21 16:40:00 to 2020-12-22 09:20:00\n",
      "Getting data from 2020-12-22 09:20:00 to 2020-12-23 02:00:00\n",
      "Getting data from 2020-12-23 02:00:00 to 2020-12-23 18:40:00\n",
      "Getting data from 2020-12-23 18:40:00 to 2020-12-24 11:20:00\n",
      "Getting data from 2020-12-24 11:20:00 to 2020-12-25 04:00:00\n",
      "Getting data from 2020-12-25 04:00:00 to 2020-12-25 20:40:00\n",
      "Getting data from 2020-12-25 20:40:00 to 2020-12-26 13:20:00\n",
      "Getting data from 2020-12-26 13:20:00 to 2020-12-27 06:00:00\n",
      "Getting data from 2020-12-27 06:00:00 to 2020-12-27 22:40:00\n",
      "Getting data from 2020-12-27 22:40:00 to 2020-12-28 15:20:00\n",
      "Getting data from 2020-12-28 15:20:00 to 2020-12-29 08:00:00\n",
      "Getting data from 2020-12-29 08:00:00 to 2020-12-30 00:40:00\n",
      "Getting data from 2020-12-30 00:40:00 to 2020-12-30 17:20:00\n",
      "Getting data from 2020-12-30 17:20:00 to 2020-12-31 10:00:00\n",
      "Getting data from 2020-12-31 10:00:00 to 2021-01-01 02:40:00\n",
      "Getting data from 2021-01-01 02:40:00 to 2021-01-01 19:20:00\n",
      "Getting data from 2021-01-01 19:20:00 to 2021-01-02 12:00:00\n",
      "Getting data from 2021-01-02 12:00:00 to 2021-01-03 04:40:00\n",
      "Getting data from 2021-01-03 04:40:00 to 2021-01-03 21:20:00\n",
      "Getting data from 2021-01-03 21:20:00 to 2021-01-04 14:00:00\n",
      "Getting data from 2021-01-04 14:00:00 to 2021-01-05 06:40:00\n",
      "Getting data from 2021-01-05 06:40:00 to 2021-01-05 23:20:00\n",
      "Getting data from 2021-01-05 23:20:00 to 2021-01-06 16:00:00\n",
      "Getting data from 2021-01-06 16:00:00 to 2021-01-07 08:40:00\n",
      "Getting data from 2021-01-07 08:40:00 to 2021-01-08 01:20:00\n",
      "Getting data from 2021-01-08 01:20:00 to 2021-01-08 18:00:00\n",
      "Getting data from 2021-01-08 18:00:00 to 2021-01-09 10:40:00\n",
      "Getting data from 2021-01-09 10:40:00 to 2021-01-10 03:20:00\n",
      "Getting data from 2021-01-10 03:20:00 to 2021-01-10 20:00:00\n",
      "Getting data from 2021-01-10 20:00:00 to 2021-01-11 12:40:00\n",
      "Getting data from 2021-01-11 12:40:00 to 2021-01-12 05:20:00\n",
      "Getting data from 2021-01-12 05:20:00 to 2021-01-12 22:00:00\n",
      "Getting data from 2021-01-12 22:00:00 to 2021-01-13 14:40:00\n",
      "Getting data from 2021-01-13 14:40:00 to 2021-01-14 07:20:00\n",
      "Getting data from 2021-01-14 07:20:00 to 2021-01-15 00:00:00\n",
      "Getting data from 2021-01-15 00:00:00 to 2021-01-15 16:40:00\n",
      "Getting data from 2021-01-15 16:40:00 to 2021-01-16 09:20:00\n",
      "Getting data from 2021-01-16 09:20:00 to 2021-01-17 02:00:00\n",
      "Getting data from 2021-01-17 02:00:00 to 2021-01-17 18:40:00\n",
      "Getting data from 2021-01-17 18:40:00 to 2021-01-18 11:20:00\n",
      "Getting data from 2021-01-18 11:20:00 to 2021-01-19 04:00:00\n",
      "Getting data from 2021-01-19 04:00:00 to 2021-01-19 20:40:00\n",
      "Getting data from 2021-01-19 20:40:00 to 2021-01-20 13:20:00\n",
      "Getting data from 2021-01-20 13:20:00 to 2021-01-21 06:00:00\n",
      "Getting data from 2021-01-21 06:00:00 to 2021-01-21 22:40:00\n",
      "Getting data from 2021-01-21 22:40:00 to 2021-01-22 15:20:00\n",
      "Getting data from 2021-01-22 15:20:00 to 2021-01-23 08:00:00\n",
      "Getting data from 2021-01-23 08:00:00 to 2021-01-24 00:40:00\n",
      "Getting data from 2021-01-24 00:40:00 to 2021-01-24 17:20:00\n",
      "Getting data from 2021-01-24 17:20:00 to 2021-01-25 10:00:00\n",
      "Getting data from 2021-01-25 10:00:00 to 2021-01-26 02:40:00\n",
      "Getting data from 2021-01-26 02:40:00 to 2021-01-26 19:20:00\n",
      "Getting data from 2021-01-26 19:20:00 to 2021-01-27 12:00:00\n",
      "Getting data from 2021-01-27 12:00:00 to 2021-01-28 04:40:00\n",
      "Getting data from 2021-01-28 04:40:00 to 2021-01-28 21:20:00\n",
      "Getting data from 2021-01-28 21:20:00 to 2021-01-29 14:00:00\n",
      "Getting data from 2021-01-29 14:00:00 to 2021-01-30 06:40:00\n",
      "Getting data from 2021-01-30 06:40:00 to 2021-01-30 23:20:00\n",
      "Getting data from 2021-01-30 23:20:00 to 2021-01-31 16:00:00\n",
      "Getting data from 2021-01-31 16:00:00 to 2021-02-01 08:40:00\n",
      "Getting data from 2021-02-01 08:40:00 to 2021-02-02 01:20:00\n",
      "Getting data from 2021-02-02 01:20:00 to 2021-02-02 18:00:00\n",
      "Getting data from 2021-02-02 18:00:00 to 2021-02-03 10:40:00\n",
      "Getting data from 2021-02-03 10:40:00 to 2021-02-04 03:20:00\n",
      "Getting data from 2021-02-04 03:20:00 to 2021-02-04 20:00:00\n",
      "Getting data from 2021-02-04 20:00:00 to 2021-02-05 12:40:00\n",
      "Getting data from 2021-02-05 12:40:00 to 2021-02-06 05:20:00\n",
      "Getting data from 2021-02-06 05:20:00 to 2021-02-06 22:00:00\n",
      "Getting data from 2021-02-06 22:00:00 to 2021-02-07 14:40:00\n",
      "Getting data from 2021-02-07 14:40:00 to 2021-02-08 07:20:00\n",
      "Getting data from 2021-02-08 07:20:00 to 2021-02-09 00:00:00\n",
      "Getting data from 2021-02-09 00:00:00 to 2021-02-09 16:40:00\n",
      "Getting data from 2021-02-09 16:40:00 to 2021-02-10 09:20:00\n",
      "Getting data from 2021-02-10 09:20:00 to 2021-02-11 02:00:00\n",
      "Getting data from 2021-02-11 02:00:00 to 2021-02-11 18:40:00\n",
      "Getting data from 2021-02-11 18:40:00 to 2021-02-12 11:20:00\n",
      "Getting data from 2021-02-12 11:20:00 to 2021-02-13 04:00:00\n",
      "Getting data from 2021-02-13 04:00:00 to 2021-02-13 20:40:00\n",
      "Getting data from 2021-02-13 20:40:00 to 2021-02-14 13:20:00\n"
     ]
    }
   ],
   "source": [
    "df2 = get_data_range(pclient, TICKER, begin, end, granularity).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>resolution_sec</th>\n",
       "      <th>fk_symbol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">ETH-EUR</th>\n",
       "      <th>2020-11-01 17:40:00</th>\n",
       "      <td>334.03</td>\n",
       "      <td>334.63</td>\n",
       "      <td>334.11</td>\n",
       "      <td>334.18</td>\n",
       "      <td>26.037805</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-01 17:35:00</th>\n",
       "      <td>334.03</td>\n",
       "      <td>334.38</td>\n",
       "      <td>334.29</td>\n",
       "      <td>334.23</td>\n",
       "      <td>10.452691</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-01 17:30:00</th>\n",
       "      <td>333.92</td>\n",
       "      <td>334.27</td>\n",
       "      <td>333.93</td>\n",
       "      <td>334.26</td>\n",
       "      <td>9.129421</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-01 17:25:00</th>\n",
       "      <td>333.67</td>\n",
       "      <td>334.82</td>\n",
       "      <td>334.66</td>\n",
       "      <td>334.00</td>\n",
       "      <td>32.089240</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-01 17:20:00</th>\n",
       "      <td>334.68</td>\n",
       "      <td>335.00</td>\n",
       "      <td>334.99</td>\n",
       "      <td>334.68</td>\n",
       "      <td>11.506148</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-14 14:45:00</th>\n",
       "      <td>1501.00</td>\n",
       "      <td>1510.31</td>\n",
       "      <td>1506.86</td>\n",
       "      <td>1501.79</td>\n",
       "      <td>155.390147</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-14 14:40:00</th>\n",
       "      <td>1502.44</td>\n",
       "      <td>1511.30</td>\n",
       "      <td>1511.30</td>\n",
       "      <td>1507.45</td>\n",
       "      <td>226.593499</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-14 14:35:00</th>\n",
       "      <td>1509.67</td>\n",
       "      <td>1519.41</td>\n",
       "      <td>1519.26</td>\n",
       "      <td>1511.53</td>\n",
       "      <td>138.201049</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-14 14:30:00</th>\n",
       "      <td>1516.79</td>\n",
       "      <td>1520.10</td>\n",
       "      <td>1520.10</td>\n",
       "      <td>1518.44</td>\n",
       "      <td>41.633719</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-14 14:25:00</th>\n",
       "      <td>1518.92</td>\n",
       "      <td>1521.74</td>\n",
       "      <td>1521.68</td>\n",
       "      <td>1520.10</td>\n",
       "      <td>73.691433</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30501 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 low     high     open    close      volume  \\\n",
       "symbol  time                                                                  \n",
       "ETH-EUR 2020-11-01 17:40:00   334.03   334.63   334.11   334.18   26.037805   \n",
       "        2020-11-01 17:35:00   334.03   334.38   334.29   334.23   10.452691   \n",
       "        2020-11-01 17:30:00   333.92   334.27   333.93   334.26    9.129421   \n",
       "        2020-11-01 17:25:00   333.67   334.82   334.66   334.00   32.089240   \n",
       "        2020-11-01 17:20:00   334.68   335.00   334.99   334.68   11.506148   \n",
       "...                              ...      ...      ...      ...         ...   \n",
       "        2021-02-14 14:45:00  1501.00  1510.31  1506.86  1501.79  155.390147   \n",
       "        2021-02-14 14:40:00  1502.44  1511.30  1511.30  1507.45  226.593499   \n",
       "        2021-02-14 14:35:00  1509.67  1519.41  1519.26  1511.53  138.201049   \n",
       "        2021-02-14 14:30:00  1516.79  1520.10  1520.10  1518.44   41.633719   \n",
       "        2021-02-14 14:25:00  1518.92  1521.74  1521.68  1520.10   73.691433   \n",
       "\n",
       "                             resolution_sec  fk_symbol  \n",
       "symbol  time                                            \n",
       "ETH-EUR 2020-11-01 17:40:00             300          1  \n",
       "        2020-11-01 17:35:00             300          1  \n",
       "        2020-11-01 17:30:00             300          1  \n",
       "        2020-11-01 17:25:00             300          1  \n",
       "        2020-11-01 17:20:00             300          1  \n",
       "...                                     ...        ...  \n",
       "        2021-02-14 14:45:00             300          1  \n",
       "        2021-02-14 14:40:00             300          1  \n",
       "        2021-02-14 14:35:00             300          1  \n",
       "        2021-02-14 14:30:00             300          1  \n",
       "        2021-02-14 14:25:00             300          1  \n",
       "\n",
       "[30501 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Get password for kenny ············\n"
     ]
    }
   ],
   "source": [
    "# again connect to the DB\n",
    "db_conn = connect2DB(\"kenny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how you store the data for sql\n",
    "reshape_data_for_db(df2).to_sql(\"candles\", db_conn, if_exists = \"append\", index = False) \n",
    "db_conn.close()\n",
    "# ?df3.to_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
